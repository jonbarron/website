<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dhruv Agarwal</title>
  
  <meta name="author" content="Dhruv Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dhruv Agarwal</name>
              </p>
              <p>I am currently an <strong> engineer </strong> at <a href="https://udaan.com"> Udaan </a> who writes AI for robots. Previously, I was as a <strong> full-stack developer </strong> at the <a href="https://www.sap.com/india/about/labs-india.html">SAP Labs India</a>.
              </p>
              <p>
                Before entering industry, I had worked with <a href="https://www.inria.fr/en/stars">STARS team</a> at <a href="https://www.inria.fr/en/inria-centre-universite-cote-dazur">Inria, Sophia Antipolis</a> as a research intern for 6 months, working on Multimodal Emotion and Personality Recognition under the supervision of <a href="http://www-sop.inria.fr/members/Francois.Bremond/">Dr. Francois Bremond</a>.
                I have also worked remotely with <a href="https://ni.www.techfak.uni-bielefeld.de/people/anmelnik">Dr. Andrew Melnik</a> from the <a href="https://www.uni-bielefeld.de/">University of Bielefeld</a> on developing neural nets to solve physics puzzles and at the <a href="https://www.maschinenbau.rwth-aachen.de/go/id/xom/lidx/1">WZL Lab, RWTH Aachen</a> developing machine learning based methods to transfer measurement uncertainties in mechanical processes.
              </p>
              <p>
                <p>
                  I did my Bachelor's in Information Technology from <a href="https://www.iiita.ac.in/">IIIT Allahabad</a>. I was advised by <a href="http://rkala.in/">Dr. Rahul Kala</a> and we worked on improving localization accuracy of traditional SLAM algorithm using Deep Learning.
                </p>
              <p>
                <p>
                  Here is my <a href="https://drive.google.com/file/d/17LDx9aoQEmAXd9JEeHJ5ml6ik64JRpZs/view?usp=sharing">Resume</a>.
                </p>    
              <p style="text-align:center">
                <a href="mailto:drv.agwl@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/drv-agwl">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=pqnGBAsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/dhruv-ag/">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/dhruv.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dhruv_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Industrial Projects</heading>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="airavat_stop()" onmouseover="airavat_start()">
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <div class="one">
              <div class="two" id='airavat'><video  width=100% height=100% muted autoplay loop>
              <source src="images/airavat_traj.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/airavat.jpg' width="160">
            </div>
            <script type="text/javascript">
              function airavat_start() {
                document.getElementById('airavat').style.opacity = "1";
              }
    
              function airavat_stop() {
                document.getElementById('airavat').style.opacity = "0";
              }
              doom_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Airavat</papertitle>
          [<a href="https://github.com/drv-agwl/Reinforcement-Learning">Code</a>]
          <p>An autonomous ground vehicle capable of navigating itself in a warehouse and localizing itself using april tags.</p>
          </td>
        </tr>
        </table>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, reinforcement learning, and physics. I am especially interested in developing real world solutions using algorithms from these domains</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/visapp_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>Multimodal Personality Recognition using Cross-Attention Transformer and Behaviour Encoding
              </papertitle>
              <br>
              <br>
              Tanay Agrawal, <strong>Dhruv Agarwal</strong>, Michal Balazia, Neelabh Sinha, Francois Bremond
              <br> 
              <em style="color: #c9314fde;">International Conference on Computer Vision Theory and Applications (VISAPP)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2112.12180">arXiv</a>

              <p>Personality recongnition using cross-attention transformers on multiple modalities and hand-crafted behaviour encodings.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/kd_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>From Multimodal to Unimodal Attention in Transformers using Knowledge
                Distillation</papertitle>
              <br>
              <br>
              <strong>Dhruv Agarwal</strong>, Tanay Agrawal, Laura M Ferrari, Francois Bremond
              <br> 
              <em style="color: #c9314fde;">Advanced Video and Signal-based Surveillance (AVSS)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2110.08270">arXiv</a>
        /
              <a href="https://docs.google.com/presentation/d/1rGbVZdNToWWN7Hu1tjELg6QmQOLFzbbnhH_Lj7hEy5o/edit?usp=sharing">Slides</a>
        
              <p>A new approach to applying knowledge distillation in transformers.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/nips_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>Solving Physics Puzzles by Reasoning about Paths</papertitle>
              <br>
              <br>
              Augustin Harter, Andrew Melnik, Gaurav Kumar, <strong>Dhruv Agarwal</strong>, Animesh Garg, Helge Ritter
              <br> 
              <em style="color: #c9314fde;">NeurIPS workshop on Interpretable Inductive Biases and Physically Structured Learning</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2011.07357">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=X30QGeIEXRs&t=5s">Video</a>
        /
              <a href="https://github.com/ndrwmlnk/PHYRE-Reasoning-about-Paths">Code</a>

              <p>A new deep learning model for goal-driven tasks that require intuitive
                physical reasoning and intervention in the scene to achieve a desired end goal.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/slam_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>SLAM and Map Learning using Hybrid Semantic Graph Optimization</papertitle>
              <br>
              <br>
              Ambuj Agrawal, <strong>Dhruv Agarwal</strong>, Mehul Arora, Ritik Mahajan, Shivansh Beohar, Lhilo Kenye, Rahul Kala. (<strong> equal contribution </strong>)
              <br> 
              <em style="color: #c9314fde;">Mediterranean Conference on Control and Automation, 2022</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9837164">Paper</a>
        
              <p>Improved localization accuracy of V-SLAM by injecting semantic information of detected corner
                points from images captured by a robot. Detected object in a scene were used for place recognition and correspondence matching which further
                enhanced the semantic information provided to V-SLAM module.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/measurement_migration_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle> Similarity assessment and model migration for measurement processes </papertitle>. <em> [Under Review] </em>
              <br>
              <br>
              <strong>Dhruv Agarwal</strong>, Meike Huber, Robert Schmitt.
              <br> 
              <em style="color: #c9314fde;">International Journal of Quality & Reliability Management (IJQRM), 2022</em>
              <br>
              <a href="https://drive.google.com/file/d/1CvJXGRnnLykAp5VzoiUAZtq44Iq8HbST/view?usp=sharing">Paper</a>
        
              <p>The determination of the measurement uncertainty is relevant for all measurement processes. In production engineering, the measurement uncertainty needs to be known to avoid erroneous decisions. However, its determination is associated to high effort due to the expertise and expenditure that is needed for modelling measurement processes. Once a measurement model is developed, it cannot necessarily be used for any other measurement process. In order to make an existing model usable for other measurement processes and thus to reduce the effort for the determination of the measurement uncertainty, a procedure for the migration of measurement models has to be developed.</p>
            </td>
          </tr>
          
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Independent Projects</heading>
      </tbody></table>
          
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/IGR.png" alt="project image" style="width:auto; height:auto; max-width:100%; max-height:120%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Unofficial Implementation of Implicit Neural Representation with Phase Loss and Fourier Features
            </papertitle>
          [<a href="https://github.com/drv-agwl/Implicit_Neural_Representation">Code</a>]
          <p>The project contains an unofficial implementation of the Phase Transitions, Distance Functions, and Implicit Neural Representations 
            <a href="https://arxiv.org/pdf/2106.07689.pdf">paper</a>. The paper proposes a new loss function, phase loss, which improves the 3D reconstruction performance for Implicit Neural Representation. The project implements the phase loss proposed in the paper and an optional fourier layer in the network which further enhances the performance for high frequency signals</p>
          </td>
        </tr>

        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/vivit_project.png" alt="project image" style="width:auto; height:auto; max-width:100%; max-height:120%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Unofficial Implementation of ViViT</papertitle>
          [<a href="https://github.com/drv-agwl/ViViT-pytorch">Code</a>]
          <p>The project contains an unofficial implementation of the Video Vision Transformer (ViViT) 
            <a href="https://arxiv.org/abs/2103.15691">paper</a>. Owing to the recent success of transformers in image classification task, 
            the paper presents a pure transformer architecture which can be exploited for video classification or for 
            extracting rich features from videos.</p>
          </td>
        </tr>  
        
        <tr onmouseout="doom_stop()" onmouseover="doom_start()">
          <!-- <td style="padding:20px;width:25%;vertical-align:middle"> -->
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <div class="one">
              <div class="two" id='doom'><video  width=100% height=100% muted autoplay loop>
              <source src="images/doom.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/doom.jpg' width="160">
            </div>
            <script type="text/javascript">
              function doom_start() {
                document.getElementById('doom').style.opacity = "1";
              }
    
              function doom_stop() {
                document.getElementById('doom').style.opacity = "0";
              }
              doom_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Deep Reinforcement Learning on Games</papertitle>
          [<a href="https://github.com/drv-agwl/Reinforcement-Learning">Code</a>]
          <p>Implementation various state-of-the-art reinforcement learning algorithms to make an AI agent learn to play
            Doom, Space Invaders, Sonic Hedgehog 2, etc.</p>
          </td>
        </tr>

        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/face-gen_project.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Face Generation</papertitle>
          [<a href="https://github.com/drv-agwl/Face-Generation-Using-DCGANs">Code</a>]
          <p>A repertoire of Deconvolutional GAN models trained to output artificial human face images. The models were trained on the <a href="https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a> dataset</p>
          </td>
        </tr> 

        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/art-gen.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Art Maker</papertitle>
          [<a href="https://github.com/drv-agwl/Neural-Style-Transfer">Code</a>]
          <p> A VGG model trained using Neural Style Transfer technique to generate artisitic images from a base image and a style image.</p>
          </td>
        </tr> 

      </tbody></table>

      <br>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;display:block;">
        <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>Blogs</heading>
            <br>
            <br>
          </td>
        </tr>

        <tr style="width: 100%; display: block;">
          <td style="padding:1%;width:25%;vertical-align:middle">
            <a  href="https://dev.to/hintiiita/getting-prepped-with-machine-learning-skills-for-a-hackathon-2nhm">
              <img src="/images/blog.png" alt="project image" style="display: block; width:auto; height:auto; max-width:50%; margin:0 auto;" >
            </a>
          </td>
        </tr>
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:small;">
              Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
            </p>
          </td>
        </tr>
      </tbody></table>

    </td>
    </tr>
  </table>
</body>

</html>
