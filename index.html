<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #2d59eb;
      text-decoration: none;
    }
    b {
      color: #e3124a;
      text-decoration: none;
    }
	  c {
      color: #21bf28;
      text-decoration: none;
    }
    a:focus,
    a:hover {
      color: #af19bf;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #daa5e0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/jose/jhuicon.png">
  <title>Jeya Maria Jose</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Jeya Maria Jose</name>
              </p>
              <p>I am a first year Ph.D. student at the <a href="https://www.jhu.edu/">Johns Hopkins University</a>, where I am working in <a href="https://engineering.jhu.edu/vpatel36/"> Vision and Image Understanding Lab </a>, advised by <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en"> Dr. Vishal M Patel </a>. 
		    </p>  
		    
		     <p> Previously, I worked with <a href="http://bioeng.nus.edu.sg/mm/principal-investigator/">Dr. Hongliang Ren</a> in the <a href="http://bioeng.nus.edu.sg/mm/">Medical Mechatronics Lab</a> at <a href="http://nus.edu.sg/">National University of Singapore</a>. I recently graduated from <a href="https://www.nitt.edu/">NIT Trichy</a> majoring in Instrumentation and Control.
              </p>
              
		<p>
              
              <p align=center>
                <a href="mailto:jeyamariajose7@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://drive.google.com/open?id=1qxZUzkfLhO0M-mvMge9tXG2zevYVLTLs">CV</a> &nbsp/&nbsp
               
                <a href="https://scholar.google.co.in/citations?user=vphpzPYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jeya-maria-jose-357951130"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/jose/dp.jpg" height = "300" width = "215">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                I work on the intersection of Computer Vision, Deep Learning and Medical Imaging. Currently, I am exploring overcomplete representations in deep learning methods and various semi-supervised learning techniques like synthetic image generation.
              </p>
            </td>
          </tr>
        </table>
	      
	      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Logs</heading>
		    <p>
		    </p>
		    <div>
		September 29, 2019 - Awarded <c href="http://cvip2019.mnit.ac.in/Award.aspx" class="text-success"> Best Student Paper award </c> at <c href = "http://cvip2019.mnit.ac.in/Default.aspx" class="text-success"> CVIP 2019 </c>. 
		    </div>
		    <div> August 29, 2019   -     Joined <c href = "https://www.jhu.edu/" class ="text-succes"> Johns Hopkins University </c> for my Ph.D with <c class = "text-success">ECE fellowship</c>.
              </div>
            </td>
          </tr>
        </table>

<heading>Projects</heading>
	      
        <table width="100%" align="center" border="0" cellspacing="20" cellpadding="20">

		 <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/CBAS.png' height="200" width="270" ></div>
                <img src='images/jose/mssa.png' height="200" width="250" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/1912.08364">
                <papertitle>Learning to Segment Brain Anatomy from 2D Ultrasound with Less Data </papertitle>
              </a>
              <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Rajeev Yasarla,
		    Puyang Wang,
		    Ilker Hacihaliloglu,
		    Vishal M. Patel
		    </p>
              
		    <p> <a href="https://arxiv.org/abs/1912.08364">Paper </a></p>
              <p> Two deep networks, a Multi-Scale Self Attention (MSSA) network for synthesis and a Confidence Based Brain Anatomy (CBAS) network for segmentation has been proposed for ultrasound modality achieving state of the art performance in each of their tasks. Moreover, we show how synthesis aids the segmentation even with less data.  </p>
            </td>
          </tr>
		
          <tr onmouseout="porlight_stop()" onmouseover="porlight_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='porlight_image'><img src='images/jose/103_fake_B.png'height="200" width="200"></div>
                <img src='images/jose/103_real_A.png' height="200" width="200">
              </div>
              <script type="text/javascript">
                function porlight_start() {
                  document.getElementById('porlight_image').style.opacity = "1";
                }
                function porlight_stop() {
                  document.getElementById('porlight_image').style.opacity = "0";
                }
                porlight_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/190082">
                 <papertitle> Tackling Multiple Visual Artifacts: Blind Image Restoration using Conditional Adversarial Networks </papertitle> 
              </a>        
		<div><b href="http://cvip2019.mnit.ac.in/"> CVIP 2019 </b> <font color="red"><b href="http://cvip2019.mnit.ac.in/Award.aspx"> (Best Student Paper Award) </b></font> 
		    </div>
			<br>    
              M Anand,
              A Ashwin Natraj,
	      <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              K Subramanian,
              S Deivalakshmi    
		    </p><a href="https://github.com/jeya-maria-jose/Image-Recovery-Using-Conditional-Adversarial-Networks"> Code </a></p>
		
		<p> Restoring images that are degraded by multiple visual artifacts like noise, blurness and other environmental visual artifacts like shadow, snow, rain and haze is a challenging task. In this work, use of conditional adversarial networks for this task has been explored.  </p>
            </td>
          </tr>
	   <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/arch3datn.png' height="200" width="270" ></div>
                <img src='images/jose/brain.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/190822">
                <papertitle>Brain Tumor Segmentation and Survival Prediction using 3D Attention UNet </papertitle>
              </a>
		    <div><b href="https://www.med.upenn.edu/cbica/brats2019/registration.html" class="text-danger">BraTS, </b> <b href="http://www.brainlesion-workshop.org/"> MICCAI Workshop 2019 </b></div>
              <br>
		    Mobarakol Islam,
		    Vibashan VS,
		    <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
		    Navodini Wijethilake,
		    Uppal Utkarsh,
		    Hongliang Ren
             
              
		    <p> <a href="https://github.com/jeya-maria-jose/Cuff_less_BP_Prediction">Code </a></p>
              <p> We adopt a 3D UNet architecture and integrate channel and spatial attention with the decoder network to perform segmen-tation. For survival prediction, we extract some novel radiomic featuresbased on geometry, location, the shape of the segmented tumor and com-bine them with clinical information to estimate the survival duration for each patient. </p>
            </td>
          </tr>
          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/cuff.gif' height="240" width="240" ></div>
                <img src='images/jose/cuff.gif' height="240" width="240" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/190822">
                <papertitle>Cuff-less Blood Pressure Prediction using Convolutional and Long Short-term Memory Networks from ECG and PPG signals  </papertitle>
              </a>
              <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              M Anand,
              Geerthy T,
	      M Siddarth,
		K Subramanian,
		    G Uma
		    </p>
		    <p> <a href="https://github.com/jeya-maria-jose/Cuff_less_BP_Prediction">Code </a></p>
              <p> In this work, an approach that does not need calibration or manual feature extraction is proposed using CNNs and LSTMs for BP prediction from ECG and PPG signals. </p>
            </td>
          </tr>
	  <tr onmouseout="cuff_stop()" onmouseover="cuff_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='cuff_image'><img src='images/jose/op.PNG' height="200" width="200" ></div>
                <img src='images/jose/brats.gif' height="200" width="200" >
              </div>
              <script type="text/javascript">
                function cuff_start() {
                  document.getElementById('cuff_image').style.opacity = "1";
                }
                function cuff_stop() {
                  document.getElementById('cuff_image').style.opacity = "0";
                }
                cuff_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.og/as/19022">
                <papertitle>Glioma Prognosis: Segmentation of the Tumor and Survival Prediction using Shape, Geometric and Clinical Information </papertitle>
              </a>
		    <div><b href="https://www.med.upenn.edu/cbica/brats2019/registration.html" class="text-danger">BraTS, </b> <b href="http://www.brainlesion-workshop.org/"> MICCAI Workshop 2018 </b></div>
              <br>
		Mobarakol Islam,
              <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Hongliang Ren
              
		    <p><a href="https://link.springer.com/chapter/10.1007/978-3-030-11726-9_13">Paper</a> | <a href="https://arxiv.org/abs/1811.02629"> Summary Paper </a> | <a href="https://drive.google.com/open?id=1e5CjKuY2dfRlT5ZEMWl0u1oehvMe_TEy">Poster</a></p>
              <p>Segmentation of brain tumor from magnetic resonance imaging (MRI) is performed using a convolutional neural network (CNN) with hypercolumn technique. Also, a variety of features are extracted from the segmented tumor to predict the overall survival in terms of number of days for each patient.   </p>
            </td>
          </tr>
	  <tr onmouseout="is_stop()" onmouseover="is_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='is_image'><img src='images/jose/isop.PNG' height="200" width="200" ></div>
                <img src='images/jose/isip.PNG' height="200" width="200" >
              </div>
              <script type="text/javascript">
                function is_start() {
                  document.getElementById('is_image').style.opacity = "1";
                }
                function is_stop() {
                  document.getElementById('is_image').style.opacity = "0";
                }
                is_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
            <a href="https://arxiv.og/abs/1904.0522">
                <papertitle>Ischemic Stroke Lesion Segmentation Using Adversarial Learning </papertitle>
		    </a>
              <br>
		    <div><b href="https://www.med.upenn.edu/cbica/brats2019/registration.html" class="text-danger">ISLES, </b> <b href="http://www.brainlesion-workshop.org/"> MICCAI Workshop 2018 </b></div>
		<p>Mobarakol Islam,
		    Rajiv V,
              <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
			Hongliang Ren</p>
              
		    <p><a href="https://link.springer.com/chapter/10.1007/978-3-030-11723-8_29">Paper</a></p>
              <p> A segmentation model with adversarial learning for ischemic lesion segmentation. U-Net with skip connection and dropout is adopted as segmentation baseline network and a fully connected network (FCN) is used as discriminator network. Three modalities (CT, DPWI, CBF) of acute computed tomography (CT) perfusion data was used to train the net.   </p>
            </td>
          </tr>
		
		
          

		 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
			<a href="https://github.com/jonbarron/jonbarron_website">source code</a> </p>
			
       

</html>
